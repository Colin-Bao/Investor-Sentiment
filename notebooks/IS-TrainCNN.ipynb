{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CNN迁移学习"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 环境导入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 01:21:49.605600: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "## 导入 Inceptionv3 模型\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "# 导入建立神经网络的基本模块\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "# 导入数据增强模块\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 超参数调节\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# 可视化\n",
    "# from keras.utils import plot_model\n",
    "# from keras_visualizer import visualizer\n",
    "# from IPython.display import Image, SVG, display\n",
    "import datetime\n",
    "\n",
    "# 回调\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_PATH_ROOT = '/data/DataSets/TWITTER_IMG_SENT_2015/dataset/'\n",
    "OUT_PATH_ROOT = '/data/Models/TWITTER_SENT_2015/'\n",
    "OUT_LOG_PATH = OUT_PATH_ROOT + 'logs/'\n",
    "\n",
    "TOTAL_EPOCH = 300"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "超参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([512, 1024]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.5, 1.0]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_L_RATE = hp.HParam('learning_rate', hp.Discrete([0.001, 0.0001]))\n",
    "METRIC_ACCURACY = 'accuracy'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 617 images belonging to 2 classes.\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 89 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 训练集\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        # rescale=1. / 255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    ")\n",
    "\n",
    "#验证集\n",
    "val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        # rescale=1. / 255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# 测试集\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, )\n",
    "\n",
    "# 数据输入\n",
    "train_generator = train_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}train', target_size=(299, 299), batch_size=617)\n",
    "val_generator = val_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}validation', target_size=(299, 299), batch_size=176)\n",
    "test_generator = test_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}test', target_size=(299, 299), batch_size=89)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 迁移学习"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 输出日志\n",
    "LOG_DIR = OUT_LOG_PATH + 'hparam_tuning/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "os.environ['TENSORBOARD_BINARY'] = '/usr/local/miniconda3/envs/TensorFlow/bin/tensorboard'\n",
    "\n",
    "# @formatter:off\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR} --port 6006 --bind_all\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def start_transfer_learning(run_dir, hparams):\n",
    "    # 构建基础模型\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)  #去掉最后一层\n",
    "\n",
    "    # 增加新的输出层\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # 添加全局平均池化层 将 MxNxC 的张量转换成 1xC 张量，C是通道数\n",
    "    x = Dense(hparams[HP_NUM_UNITS], activation='relu')(x)  # 添加一个全连接层\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)  # 添加一个隐藏层\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 自定义自己的分类器，这是一个2分类的分类器\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)  # 构建我们需要训练的完整模型\n",
    "\n",
    "    # 锁层\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # 编译模型\n",
    "    # if hparams[HP_OPTIMIZER] == \"adam\":\n",
    "    #     optimizer = Adam(learning_rate=hparams[HP_L_RATE])\n",
    "    # elif hparams[HP_OPTIMIZER] == \"sgd\":\n",
    "    #     optimizer = SGD(learning_rate=hparams[HP_L_RATE])\n",
    "    # else:\n",
    "    #     raise ValueError(\"unexpected optimizer name\")\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER], loss='categorical_crossentropy', metrics=['accuracy'])  # rmsprop\n",
    "\n",
    "    # 训练\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch=1,  #800\n",
    "              epochs=TOTAL_EPOCH,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=1,\n",
    "              validation_freq=20,\n",
    "              class_weight=None,  # 样本是均衡的\n",
    "              callbacks=\n",
    "              [\n",
    "                      TensorBoard(log_dir=run_dir),  #可视化\n",
    "                      hp.KerasCallback(run_dir, hparams),  #超参数\n",
    "                      EarlyStopping(monitor='val_acc', patience=20),  # 早停选项\n",
    "                      ReduceLROnPlateau(monitor='val_acc', patience=20),  # 学习率衰减\n",
    "                      ModelCheckpoint(run_dir, monitor='val_acc', save_best_only=True, save_freq=20)  #检查点\n",
    "\n",
    "              ],\n",
    "              # workers=1,\n",
    "              )\n",
    "    # 在测试集上评估 profile_batch=5, histogram_freq=1\n",
    "    # scores = model.evaluate_generator(test_generator)\n",
    "\n",
    "    # return scores\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 超参数调整"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 超参数运行\n",
    "def run_hparams():\n",
    "    session_num = 0\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for dropout_rate in HP_DROPOUT.domain.values:\n",
    "            for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                # for learning_rate in HP_L_RATE.domain.values:\n",
    "                start_transfer_learning(\n",
    "                        LOG_DIR + f'run-{session_num}',\n",
    "                        {\n",
    "                                HP_NUM_UNITS: num_units,\n",
    "                                HP_DROPOUT  : dropout_rate,\n",
    "                                HP_OPTIMIZER: optimizer,\n",
    "                                # HP_L_RATE   : learning_rate,\n",
    "                        }\n",
    "                )\n",
    "                session_num += 1\n",
    "\n",
    "\n",
    "run_hparams()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "TensorFlow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
