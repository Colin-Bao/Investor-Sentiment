{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CNN迁移学习"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 环境导入"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 02:50:39.277647: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "## 导入 Inceptionv3 模型\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "\n",
    "# 导入建立神经网络的基本模块\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "\n",
    "from keras.optimizers import *\n",
    "from keras.losses import categorical_crossentropy\n",
    "\n",
    "# 导入数据增强模块\n",
    "import cv2\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# 超参数调节\n",
    "import tensorflow as tf\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "\n",
    "# 可视化\n",
    "# from keras.utils import plot_model\n",
    "# from keras_visualizer import visualizer\n",
    "# from IPython.display import Image, SVG, display\n",
    "import datetime\n",
    "\n",
    "# 回调\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 参数区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "DATASET_PATH_ROOT = '/data/DataSets/TWITTER_IMG_SENT_2015/dataset/'\n",
    "OUT_PATH_ROOT = '/data/Models/TWITTER_SENT_2015/'\n",
    "OUT_LOG_PATH = OUT_PATH_ROOT + 'logs/'\n",
    "\n",
    "TOTAL_EPOCH = 300"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "超参数"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([512, 1024]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.Discrete([0.5, 1.0]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "HP_L_RATE = hp.HParam('learning_rate', hp.Discrete([0.001, 0.0001]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 617 images belonging to 2 classes.\n",
      "Found 176 images belonging to 2 classes.\n",
      "Found 89 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# 训练集\n",
    "train_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        # rescale=1. / 255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    ")\n",
    "\n",
    "#验证集\n",
    "val_datagen = ImageDataGenerator(\n",
    "        preprocessing_function=preprocess_input,\n",
    "        # rescale=1. / 255,\n",
    "        rotation_range=30,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    ")\n",
    "\n",
    "# 测试集\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, )\n",
    "\n",
    "# 数据输入\n",
    "train_generator = train_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}train', target_size=(299, 299), batch_size=617)\n",
    "val_generator = val_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}validation', target_size=(299, 299), batch_size=176)\n",
    "test_generator = test_datagen.flow_from_directory(directory=f'{DATASET_PATH_ROOT}test', target_size=(299, 299), batch_size=89)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 迁移学习"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 输出日志\n",
    "LOG_DIR = OUT_LOG_PATH + 'hparam_tuning/' + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + '/'\n",
    "os.environ['TENSORBOARD_BINARY'] = '/usr/local/miniconda3/envs/TensorFlow/bin/tensorboard'\n",
    "\n",
    "# @formatter:off\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir {LOG_DIR} --port 6006 --bind_all\n",
    "# @formatter:on"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def start_transfer_learning(run_dir, hparams):\n",
    "    # 构建基础模型\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False)  #去掉最后一层\n",
    "\n",
    "    # 增加新的输出层\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # 添加全局平均池化层 将 MxNxC 的张量转换成 1xC 张量，C是通道数\n",
    "    x = Dense(hparams[HP_NUM_UNITS], activation='relu')(x)  # 添加一个全连接层\n",
    "    x = Dropout(hparams[HP_DROPOUT])(x)  # 添加一个隐藏层\n",
    "    predictions = Dense(2, activation='softmax')(x)  # 自定义自己的分类器，这是一个2分类的分类器\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)  # 构建我们需要训练的完整模型\n",
    "\n",
    "    # 锁层\n",
    "    base_model.trainable = False\n",
    "    # base_model.summary()\n",
    "\n",
    "    # 编译模型\n",
    "    # if hparams[HP_OPTIMIZER] == \"adam\":\n",
    "    #     optimizer = Adam(learning_rate=hparams[HP_L_RATE])\n",
    "    # elif hparams[HP_OPTIMIZER] == \"sgd\":\n",
    "    #     optimizer = SGD(learning_rate=hparams[HP_L_RATE])\n",
    "    # else:\n",
    "    #     raise ValueError(\"unexpected optimizer name\")\n",
    "    model.compile(optimizer=hparams[HP_OPTIMIZER], loss='categorical_crossentropy', metrics=['accuracy'])  # rmsprop\n",
    "\n",
    "    # 训练\n",
    "    model.fit(train_generator,\n",
    "              steps_per_epoch=1,  #800\n",
    "              epochs=TOTAL_EPOCH,\n",
    "              validation_data=val_generator,\n",
    "              validation_steps=1,\n",
    "              validation_freq=20,  # 验证频率\n",
    "              class_weight=None,  # 样本是均衡的\n",
    "              callbacks=\n",
    "              [TensorBoard(log_dir=run_dir),  #可视化\n",
    "               hp.KerasCallback(run_dir, hparams),  #超参数\n",
    "               EarlyStopping(monitor='val_accuracy', patience=20),  # 早停选项\n",
    "               ReduceLROnPlateau(monitor='val_accuracy', patience=20),  # 学习率衰减\n",
    "               ModelCheckpoint(f'{run_dir}/Twitter2015_iv3_tl.h5', monitor='val_accuracy', save_best_only=True, save_freq='epoch')  #检查点\n",
    "               ],\n",
    "              workers=5,  # 线程\n",
    "              )\n",
    "\n",
    "    # 在测试集上评估\n",
    "    # scores = model.evaluate_generator(test_generator)\n",
    "    # print(scores)\n",
    "\n",
    "    # return scores\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 超参数调整"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 02:50:44.143326: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.151541: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.153103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.154911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 02:50:44.155488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.157047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.158499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.953027: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.954636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.956113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-01-07 02:50:44.957557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30964 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:08.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 02:51:17.421649: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "2023-01-07 02:51:18.220446: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - ETA: 0s - loss: 1.0789 - accuracy: 0.3955WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 33s 33s/step - loss: 1.0789 - accuracy: 0.3955 - lr: 0.0010\n",
      "Epoch 2/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 5.1876 - accuracy: 0.6726WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 5.1876 - accuracy: 0.6726 - lr: 0.0010\n",
      "Epoch 3/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 3.6470 - accuracy: 0.6726WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 3.6470 - accuracy: 0.6726 - lr: 0.0010\n",
      "Epoch 4/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.7597 - accuracy: 0.6726WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 1.7597 - accuracy: 0.6726 - lr: 0.0010\n",
      "Epoch 5/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.6327 - accuracy: 0.6791WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.6327 - accuracy: 0.6791 - lr: 0.0010\n",
      "Epoch 6/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.8662 - accuracy: 0.3971WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.8662 - accuracy: 0.3971 - lr: 0.0010\n",
      "Epoch 7/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9838 - accuracy: 0.3404WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.9838 - accuracy: 0.3404 - lr: 0.0010\n",
      "Epoch 8/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.9045 - accuracy: 0.3323WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.9045 - accuracy: 0.3323 - lr: 0.0010\n",
      "Epoch 9/300\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.7535 - accuracy: 0.4003WARNING:tensorflow:Early stopping conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_accuracy` which is not available. Available metrics are: loss,accuracy,lr\n",
      "WARNING:tensorflow:Can save best model only with val_accuracy available, skipping.\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.7535 - accuracy: 0.4003 - lr: 0.0010\n",
      "Epoch 10/300\n"
     ]
    }
   ],
   "source": [
    "# 超参数运行\n",
    "def run_hparams():\n",
    "    session_num = 0\n",
    "    for num_units in HP_NUM_UNITS.domain.values:\n",
    "        for dropout_rate in HP_DROPOUT.domain.values:\n",
    "            for optimizer in HP_OPTIMIZER.domain.values:\n",
    "                # for learning_rate in HP_L_RATE.domain.values:\n",
    "                start_transfer_learning(\n",
    "                        LOG_DIR + f'run-{session_num}',\n",
    "                        {\n",
    "                                HP_NUM_UNITS: num_units,\n",
    "                                HP_DROPOUT  : dropout_rate,\n",
    "                                HP_OPTIMIZER: optimizer,\n",
    "                                # HP_L_RATE   : learning_rate,\n",
    "                        }\n",
    "                )\n",
    "                session_num += 1\n",
    "\n",
    "\n",
    "run_hparams()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tensorflow",
   "language": "python",
   "display_name": "TensorFlow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
