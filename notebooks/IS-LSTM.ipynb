{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 股价预测专题"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 11:53:40.153207: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "# 必要的库\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler  # 进行归一化操作\n",
    "\n",
    "# 自行编写的包\n",
    "sys.path.append('/home/ubuntu/notebooks/pycharm_projects/Investor-Sentiment')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 数据准备"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 参数区"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 特征工程和数据集\n",
    "factor_column = ['close', 'img_neg', 'tex_neg', 'SENT_INDEX', 'SENT_INDEX_R']\n",
    "# factor_column = ['close']\n",
    "df_data = pd.read_csv('/data/DataSets/investor_sentiment/FINAL_DATA_2014_2021.csv', usecols=factor_column)\n",
    "df_data = df_data[factor_column]  #第一个是标签\n",
    "\n",
    "# 参数区\n",
    "TIME_STEPS = 1  # 时间窗\n",
    "FORECAST_STEPS = 5  # 未来步长\n",
    "BATCH_SIZE = 1024\n",
    "EPOCHS = 500\n",
    "FEATURES = len(factor_column)  # 特征\n",
    "train_size, val_size = int(len(df_data) * 0.6), int(len(df_data) * 0.8)  #训练集,测试集"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "          close   img_neg   tex_neg  SENT_INDEX  SENT_INDEX_R\n0     2900.6300  0.000000  0.000000   -0.932715     -1.191905\n1     2874.3200  0.000000  0.333333   -0.928031     -1.182604\n2     2803.2900  0.285714  0.142857   -0.917702     -1.175354\n3     2814.1000  0.000000  0.333333   -0.914326     -1.172984\n4     2825.8200  0.333333  0.000000   -0.931606     -1.185114\n...         ...       ...       ...         ...           ...\n1939  5897.1579  0.220339  0.152542    0.597233      0.390557\n1940  5939.4153  0.047619  0.238095    1.426782      1.186737\n1941  5885.3073  0.250000  0.350000    0.202870      0.013389\n1942  5935.2719  0.388889  0.277778    1.203630      0.972127\n1943  5969.8001  0.142857  0.047619    0.902235      0.720920\n\n[1944 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>close</th>\n      <th>img_neg</th>\n      <th>tex_neg</th>\n      <th>SENT_INDEX</th>\n      <th>SENT_INDEX_R</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2900.6300</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>-0.932715</td>\n      <td>-1.191905</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2874.3200</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>-0.928031</td>\n      <td>-1.182604</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2803.2900</td>\n      <td>0.285714</td>\n      <td>0.142857</td>\n      <td>-0.917702</td>\n      <td>-1.175354</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2814.1000</td>\n      <td>0.000000</td>\n      <td>0.333333</td>\n      <td>-0.914326</td>\n      <td>-1.172984</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2825.8200</td>\n      <td>0.333333</td>\n      <td>0.000000</td>\n      <td>-0.931606</td>\n      <td>-1.185114</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1939</th>\n      <td>5897.1579</td>\n      <td>0.220339</td>\n      <td>0.152542</td>\n      <td>0.597233</td>\n      <td>0.390557</td>\n    </tr>\n    <tr>\n      <th>1940</th>\n      <td>5939.4153</td>\n      <td>0.047619</td>\n      <td>0.238095</td>\n      <td>1.426782</td>\n      <td>1.186737</td>\n    </tr>\n    <tr>\n      <th>1941</th>\n      <td>5885.3073</td>\n      <td>0.250000</td>\n      <td>0.350000</td>\n      <td>0.202870</td>\n      <td>0.013389</td>\n    </tr>\n    <tr>\n      <th>1942</th>\n      <td>5935.2719</td>\n      <td>0.388889</td>\n      <td>0.277778</td>\n      <td>1.203630</td>\n      <td>0.972127</td>\n    </tr>\n    <tr>\n      <th>1943</th>\n      <td>5969.8001</td>\n      <td>0.142857</td>\n      <td>0.047619</td>\n      <td>0.902235</td>\n      <td>0.720920</td>\n    </tr>\n  </tbody>\n</table>\n<p>1944 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 数据集转换"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((384, 1, 5), (384, 5))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 归一化 将数据缩放到 [0, 1] 范围内\n",
    "Scaler = MinMaxScaler()\n",
    "df_std = Scaler.fit_transform(df_data)\n",
    "\n",
    "# 将数据集分为训练集,验证集和测试集\n",
    "train_data, val_data, test_data = df_std[0:train_size, :], df_std[train_size:val_size, :], df_std[val_size:, :]\n",
    "\n",
    "\n",
    "# 将时间序列数据转换为监督学习数据\n",
    "def create_dataset(dataset, look_back=TIME_STEPS, forecast=FORECAST_STEPS):\n",
    "    x, y = [], []\n",
    "    for i in range(len(dataset) - look_back - forecast + 1):\n",
    "        x.append(dataset[i:(i + look_back), :])  # 已经包含了过去的数据\n",
    "        y.append(dataset[(i + look_back):(i + look_back + forecast), 0])  #第一个是标签,标签延后了一天\n",
    "    return np.array(x), np.array(y)\n",
    "\n",
    "\n",
    "# 生成训练集和测试集\n",
    "train_X, train_Y = create_dataset(train_data, TIME_STEPS)\n",
    "val_X, val_Y = create_dataset(val_data, TIME_STEPS)\n",
    "test_X, test_Y = create_dataset(test_data, TIME_STEPS)\n",
    "test_X.shape, test_Y.shape,  # [样本数, 时间步数, 特征数]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型构建"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 11:53:41.519811: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:41.526722: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:41.528268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:41.530132: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-12 11:53:41.530874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:41.532454: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:41.534009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:42.324139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:42.325679: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:42.327221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-12 11:53:42.328638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30964 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:00:09.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 1, 64)             17920     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 1, 64)             33024     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 1, 64)             33024     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1, 64)             0         \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 325       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117,317\n",
      "Trainable params: 117,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 构建LSTM模型\n",
    "model = Sequential([\n",
    "        LSTM(units=64, input_shape=(TIME_STEPS, FEATURES), return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=64, return_sequences=True),\n",
    "        Dropout(0.2),\n",
    "        LSTM(units=64),\n",
    "        Dropout(0.2),\n",
    "        Dense(units=FORECAST_STEPS, activation='sigmoid')  #预测步长\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 模型训练"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 11:53:48.327255: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8401\n",
      "Could not load symbol cublasGetSmCountTarget from libcublas.so.11. Error: /usr/local/miniconda3/envs/Rapids/lib/python3.9/site-packages/tensorflow/python/../../../../libcublas.so.11: undefined symbol: cublasGetSmCountTarget\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 6s - loss: 0.6931 - accuracy: 0.1637 - val_loss: 0.6922 - val_accuracy: 0.1641 - 6s/epoch - 3s/step\n",
      "Epoch 2/500\n",
      "2/2 - 0s - loss: 0.6924 - accuracy: 0.1619 - val_loss: 0.6912 - val_accuracy: 0.1641 - 33ms/epoch - 16ms/step\n",
      "Epoch 3/500\n",
      "2/2 - 0s - loss: 0.6917 - accuracy: 0.1671 - val_loss: 0.6901 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 4/500\n",
      "2/2 - 0s - loss: 0.6909 - accuracy: 0.1628 - val_loss: 0.6890 - val_accuracy: 0.1641 - 35ms/epoch - 17ms/step\n",
      "Epoch 5/500\n",
      "2/2 - 0s - loss: 0.6901 - accuracy: 0.1671 - val_loss: 0.6878 - val_accuracy: 0.1641 - 34ms/epoch - 17ms/step\n",
      "Epoch 6/500\n",
      "2/2 - 0s - loss: 0.6892 - accuracy: 0.1697 - val_loss: 0.6865 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 7/500\n",
      "2/2 - 0s - loss: 0.6883 - accuracy: 0.1628 - val_loss: 0.6851 - val_accuracy: 0.1641 - 48ms/epoch - 24ms/step\n",
      "Epoch 8/500\n",
      "2/2 - 0s - loss: 0.6873 - accuracy: 0.1611 - val_loss: 0.6836 - val_accuracy: 0.1641 - 32ms/epoch - 16ms/step\n",
      "Epoch 9/500\n",
      "2/2 - 0s - loss: 0.6862 - accuracy: 0.1619 - val_loss: 0.6819 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 10/500\n",
      "2/2 - 0s - loss: 0.6850 - accuracy: 0.1585 - val_loss: 0.6801 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 11/500\n",
      "2/2 - 0s - loss: 0.6837 - accuracy: 0.1611 - val_loss: 0.6780 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 12/500\n",
      "2/2 - 0s - loss: 0.6822 - accuracy: 0.1671 - val_loss: 0.6757 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 13/500\n",
      "2/2 - 0s - loss: 0.6807 - accuracy: 0.1671 - val_loss: 0.6731 - val_accuracy: 0.1641 - 33ms/epoch - 17ms/step\n",
      "Epoch 14/500\n",
      "2/2 - 0s - loss: 0.6789 - accuracy: 0.1645 - val_loss: 0.6701 - val_accuracy: 0.1641 - 33ms/epoch - 16ms/step\n",
      "Epoch 15/500\n",
      "2/2 - 0s - loss: 0.6768 - accuracy: 0.1723 - val_loss: 0.6668 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 16/500\n",
      "2/2 - 0s - loss: 0.6745 - accuracy: 0.1593 - val_loss: 0.6630 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 17/500\n",
      "2/2 - 0s - loss: 0.6721 - accuracy: 0.1662 - val_loss: 0.6586 - val_accuracy: 0.1641 - 29ms/epoch - 15ms/step\n",
      "Epoch 18/500\n",
      "2/2 - 0s - loss: 0.6693 - accuracy: 0.1671 - val_loss: 0.6536 - val_accuracy: 0.1641 - 29ms/epoch - 15ms/step\n",
      "Epoch 19/500\n",
      "2/2 - 0s - loss: 0.6663 - accuracy: 0.1688 - val_loss: 0.6479 - val_accuracy: 0.1641 - 29ms/epoch - 15ms/step\n",
      "Epoch 20/500\n",
      "2/2 - 0s - loss: 0.6630 - accuracy: 0.1637 - val_loss: 0.6415 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 21/500\n",
      "2/2 - 0s - loss: 0.6595 - accuracy: 0.1619 - val_loss: 0.6344 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 22/500\n",
      "2/2 - 0s - loss: 0.6558 - accuracy: 0.1628 - val_loss: 0.6270 - val_accuracy: 0.1641 - 32ms/epoch - 16ms/step\n",
      "Epoch 23/500\n",
      "2/2 - 0s - loss: 0.6519 - accuracy: 0.1611 - val_loss: 0.6194 - val_accuracy: 0.1641 - 33ms/epoch - 16ms/step\n",
      "Epoch 24/500\n",
      "2/2 - 0s - loss: 0.6494 - accuracy: 0.1697 - val_loss: 0.6121 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 25/500\n",
      "2/2 - 0s - loss: 0.6478 - accuracy: 0.1576 - val_loss: 0.6062 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 26/500\n",
      "2/2 - 0s - loss: 0.6465 - accuracy: 0.1611 - val_loss: 0.6023 - val_accuracy: 0.1641 - 31ms/epoch - 15ms/step\n",
      "Epoch 27/500\n",
      "2/2 - 0s - loss: 0.6468 - accuracy: 0.1550 - val_loss: 0.6002 - val_accuracy: 0.1641 - 32ms/epoch - 16ms/step\n",
      "Epoch 28/500\n",
      "2/2 - 0s - loss: 0.6466 - accuracy: 0.1723 - val_loss: 0.5992 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 29/500\n",
      "2/2 - 0s - loss: 0.6458 - accuracy: 0.1576 - val_loss: 0.5991 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 30/500\n",
      "2/2 - 0s - loss: 0.6443 - accuracy: 0.1680 - val_loss: 0.5997 - val_accuracy: 0.1641 - 29ms/epoch - 15ms/step\n",
      "Epoch 31/500\n",
      "2/2 - 0s - loss: 0.6440 - accuracy: 0.1619 - val_loss: 0.6006 - val_accuracy: 0.1641 - 28ms/epoch - 14ms/step\n",
      "Epoch 32/500\n",
      "2/2 - 0s - loss: 0.6425 - accuracy: 0.1723 - val_loss: 0.6019 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 33/500\n",
      "2/2 - 0s - loss: 0.6417 - accuracy: 0.1774 - val_loss: 0.6030 - val_accuracy: 0.1641 - 34ms/epoch - 17ms/step\n",
      "Epoch 34/500\n",
      "2/2 - 0s - loss: 0.6411 - accuracy: 0.2076 - val_loss: 0.6036 - val_accuracy: 0.1328 - 32ms/epoch - 16ms/step\n",
      "Epoch 35/500\n",
      "2/2 - 0s - loss: 0.6411 - accuracy: 0.1766 - val_loss: 0.6038 - val_accuracy: 0.1328 - 32ms/epoch - 16ms/step\n",
      "Epoch 36/500\n",
      "2/2 - 0s - loss: 0.6407 - accuracy: 0.1809 - val_loss: 0.6035 - val_accuracy: 0.1328 - 34ms/epoch - 17ms/step\n",
      "Epoch 37/500\n",
      "2/2 - 0s - loss: 0.6404 - accuracy: 0.2110 - val_loss: 0.6026 - val_accuracy: 0.1797 - 31ms/epoch - 16ms/step\n",
      "Epoch 38/500\n",
      "2/2 - 0s - loss: 0.6399 - accuracy: 0.1929 - val_loss: 0.6017 - val_accuracy: 0.2396 - 30ms/epoch - 15ms/step\n",
      "Epoch 39/500\n",
      "2/2 - 0s - loss: 0.6390 - accuracy: 0.2145 - val_loss: 0.6009 - val_accuracy: 0.2396 - 30ms/epoch - 15ms/step\n",
      "Epoch 40/500\n",
      "2/2 - 0s - loss: 0.6387 - accuracy: 0.2033 - val_loss: 0.6001 - val_accuracy: 0.2396 - 29ms/epoch - 15ms/step\n",
      "Epoch 41/500\n",
      "2/2 - 0s - loss: 0.6377 - accuracy: 0.1938 - val_loss: 0.5992 - val_accuracy: 0.2396 - 29ms/epoch - 14ms/step\n",
      "Epoch 42/500\n",
      "2/2 - 0s - loss: 0.6380 - accuracy: 0.1774 - val_loss: 0.5983 - val_accuracy: 0.2396 - 29ms/epoch - 14ms/step\n",
      "Epoch 43/500\n",
      "2/2 - 0s - loss: 0.6369 - accuracy: 0.1921 - val_loss: 0.5973 - val_accuracy: 0.2396 - 30ms/epoch - 15ms/step\n",
      "Epoch 44/500\n",
      "2/2 - 0s - loss: 0.6369 - accuracy: 0.1878 - val_loss: 0.5965 - val_accuracy: 0.2396 - 32ms/epoch - 16ms/step\n",
      "Epoch 45/500\n",
      "2/2 - 0s - loss: 0.6357 - accuracy: 0.1938 - val_loss: 0.5959 - val_accuracy: 0.2396 - 32ms/epoch - 16ms/step\n",
      "Epoch 46/500\n",
      "2/2 - 0s - loss: 0.6354 - accuracy: 0.2084 - val_loss: 0.5956 - val_accuracy: 0.2396 - 32ms/epoch - 16ms/step\n",
      "Epoch 47/500\n",
      "2/2 - 0s - loss: 0.6345 - accuracy: 0.1809 - val_loss: 0.5955 - val_accuracy: 0.2396 - 30ms/epoch - 15ms/step\n",
      "Epoch 48/500\n",
      "2/2 - 0s - loss: 0.6336 - accuracy: 0.1895 - val_loss: 0.5956 - val_accuracy: 0.2396 - 31ms/epoch - 15ms/step\n",
      "Epoch 49/500\n",
      "2/2 - 0s - loss: 0.6327 - accuracy: 0.2093 - val_loss: 0.5956 - val_accuracy: 0.2578 - 29ms/epoch - 15ms/step\n",
      "Epoch 50/500\n",
      "2/2 - 0s - loss: 0.6317 - accuracy: 0.1964 - val_loss: 0.5956 - val_accuracy: 0.2734 - 29ms/epoch - 14ms/step\n",
      "Epoch 51/500\n",
      "2/2 - 0s - loss: 0.6307 - accuracy: 0.1990 - val_loss: 0.5954 - val_accuracy: 0.3073 - 30ms/epoch - 15ms/step\n",
      "Epoch 52/500\n",
      "2/2 - 0s - loss: 0.6295 - accuracy: 0.2050 - val_loss: 0.5949 - val_accuracy: 0.3073 - 30ms/epoch - 15ms/step\n",
      "Epoch 53/500\n",
      "2/2 - 0s - loss: 0.6281 - accuracy: 0.2016 - val_loss: 0.5941 - val_accuracy: 0.2734 - 30ms/epoch - 15ms/step\n",
      "Epoch 54/500\n",
      "2/2 - 0s - loss: 0.6262 - accuracy: 0.1817 - val_loss: 0.5932 - val_accuracy: 0.2188 - 29ms/epoch - 15ms/step\n",
      "Epoch 55/500\n",
      "2/2 - 0s - loss: 0.6247 - accuracy: 0.2076 - val_loss: 0.5926 - val_accuracy: 0.1875 - 29ms/epoch - 15ms/step\n",
      "Epoch 56/500\n",
      "2/2 - 0s - loss: 0.6226 - accuracy: 0.1998 - val_loss: 0.5921 - val_accuracy: 0.1693 - 30ms/epoch - 15ms/step\n",
      "Epoch 57/500\n",
      "2/2 - 0s - loss: 0.6192 - accuracy: 0.2050 - val_loss: 0.5915 - val_accuracy: 0.1562 - 30ms/epoch - 15ms/step\n",
      "Epoch 58/500\n",
      "2/2 - 0s - loss: 0.6169 - accuracy: 0.2102 - val_loss: 0.5912 - val_accuracy: 0.1510 - 33ms/epoch - 16ms/step\n",
      "Epoch 59/500\n",
      "2/2 - 0s - loss: 0.6145 - accuracy: 0.2076 - val_loss: 0.5909 - val_accuracy: 0.1615 - 31ms/epoch - 15ms/step\n",
      "Epoch 60/500\n",
      "2/2 - 0s - loss: 0.6117 - accuracy: 0.1998 - val_loss: 0.5905 - val_accuracy: 0.1589 - 31ms/epoch - 16ms/step\n",
      "Epoch 61/500\n",
      "2/2 - 0s - loss: 0.6089 - accuracy: 0.2041 - val_loss: 0.5902 - val_accuracy: 0.1589 - 30ms/epoch - 15ms/step\n",
      "Epoch 62/500\n",
      "2/2 - 0s - loss: 0.6053 - accuracy: 0.2059 - val_loss: 0.5897 - val_accuracy: 0.1589 - 29ms/epoch - 15ms/step\n",
      "Epoch 63/500\n",
      "2/2 - 0s - loss: 0.6026 - accuracy: 0.2059 - val_loss: 0.5889 - val_accuracy: 0.1589 - 29ms/epoch - 15ms/step\n",
      "Epoch 64/500\n",
      "2/2 - 0s - loss: 0.5993 - accuracy: 0.1886 - val_loss: 0.5885 - val_accuracy: 0.1615 - 30ms/epoch - 15ms/step\n",
      "Epoch 65/500\n",
      "2/2 - 0s - loss: 0.5968 - accuracy: 0.2084 - val_loss: 0.5888 - val_accuracy: 0.1693 - 29ms/epoch - 15ms/step\n",
      "Epoch 66/500\n",
      "2/2 - 0s - loss: 0.5938 - accuracy: 0.1938 - val_loss: 0.5892 - val_accuracy: 0.1771 - 30ms/epoch - 15ms/step\n",
      "Epoch 67/500\n",
      "2/2 - 0s - loss: 0.5921 - accuracy: 0.1929 - val_loss: 0.5894 - val_accuracy: 0.1797 - 29ms/epoch - 14ms/step\n",
      "Epoch 68/500\n",
      "2/2 - 0s - loss: 0.5900 - accuracy: 0.2033 - val_loss: 0.5896 - val_accuracy: 0.1797 - 30ms/epoch - 15ms/step\n",
      "Epoch 69/500\n",
      "2/2 - 0s - loss: 0.5873 - accuracy: 0.1998 - val_loss: 0.5895 - val_accuracy: 0.1719 - 30ms/epoch - 15ms/step\n",
      "Epoch 70/500\n",
      "2/2 - 0s - loss: 0.5848 - accuracy: 0.2050 - val_loss: 0.5891 - val_accuracy: 0.1797 - 32ms/epoch - 16ms/step\n",
      "Epoch 71/500\n",
      "2/2 - 0s - loss: 0.5836 - accuracy: 0.2145 - val_loss: 0.5885 - val_accuracy: 0.1797 - 34ms/epoch - 17ms/step\n",
      "Epoch 72/500\n",
      "2/2 - 0s - loss: 0.5818 - accuracy: 0.2283 - val_loss: 0.5878 - val_accuracy: 0.1771 - 32ms/epoch - 16ms/step\n",
      "Epoch 73/500\n",
      "2/2 - 0s - loss: 0.5794 - accuracy: 0.2067 - val_loss: 0.5868 - val_accuracy: 0.1771 - 29ms/epoch - 15ms/step\n",
      "Epoch 74/500\n",
      "2/2 - 0s - loss: 0.5776 - accuracy: 0.2102 - val_loss: 0.5858 - val_accuracy: 0.1719 - 30ms/epoch - 15ms/step\n",
      "Epoch 75/500\n",
      "2/2 - 0s - loss: 0.5755 - accuracy: 0.1852 - val_loss: 0.5847 - val_accuracy: 0.1693 - 30ms/epoch - 15ms/step\n",
      "Epoch 76/500\n",
      "2/2 - 0s - loss: 0.5738 - accuracy: 0.1929 - val_loss: 0.5838 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 77/500\n",
      "2/2 - 0s - loss: 0.5725 - accuracy: 0.2093 - val_loss: 0.5831 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 78/500\n",
      "2/2 - 0s - loss: 0.5711 - accuracy: 0.1964 - val_loss: 0.5823 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 79/500\n",
      "2/2 - 0s - loss: 0.5704 - accuracy: 0.2127 - val_loss: 0.5819 - val_accuracy: 0.1641 - 32ms/epoch - 16ms/step\n",
      "Epoch 80/500\n",
      "2/2 - 0s - loss: 0.5694 - accuracy: 0.2136 - val_loss: 0.5818 - val_accuracy: 0.1641 - 33ms/epoch - 17ms/step\n",
      "Epoch 81/500\n",
      "2/2 - 0s - loss: 0.5689 - accuracy: 0.1904 - val_loss: 0.5817 - val_accuracy: 0.1641 - 33ms/epoch - 17ms/step\n",
      "Epoch 82/500\n",
      "2/2 - 0s - loss: 0.5684 - accuracy: 0.1964 - val_loss: 0.5814 - val_accuracy: 0.1641 - 34ms/epoch - 17ms/step\n",
      "Epoch 83/500\n",
      "2/2 - 0s - loss: 0.5678 - accuracy: 0.2127 - val_loss: 0.5815 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 84/500\n",
      "2/2 - 0s - loss: 0.5673 - accuracy: 0.2214 - val_loss: 0.5816 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 85/500\n",
      "2/2 - 0s - loss: 0.5671 - accuracy: 0.2102 - val_loss: 0.5820 - val_accuracy: 0.1641 - 29ms/epoch - 15ms/step\n",
      "Epoch 86/500\n",
      "2/2 - 0s - loss: 0.5671 - accuracy: 0.2059 - val_loss: 0.5826 - val_accuracy: 0.1641 - 30ms/epoch - 15ms/step\n",
      "Epoch 87/500\n",
      "2/2 - 0s - loss: 0.5673 - accuracy: 0.1998 - val_loss: 0.5827 - val_accuracy: 0.1641 - 31ms/epoch - 15ms/step\n",
      "Epoch 88/500\n",
      "2/2 - 0s - loss: 0.5672 - accuracy: 0.1860 - val_loss: 0.5827 - val_accuracy: 0.1641 - 32ms/epoch - 16ms/step\n",
      "Epoch 89/500\n",
      "2/2 - 0s - loss: 0.5672 - accuracy: 0.2033 - val_loss: 0.5826 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 90/500\n",
      "2/2 - 0s - loss: 0.5671 - accuracy: 0.1998 - val_loss: 0.5830 - val_accuracy: 0.1641 - 31ms/epoch - 16ms/step\n",
      "Epoch 91/500\n",
      "2/2 - 0s - loss: 0.5666 - accuracy: 0.1972 - val_loss: 0.5833 - val_accuracy: 0.1589 - 33ms/epoch - 17ms/step\n",
      "Epoch 92/500\n",
      "2/2 - 0s - loss: 0.5666 - accuracy: 0.2102 - val_loss: 0.5829 - val_accuracy: 0.1823 - 35ms/epoch - 17ms/step\n",
      "Epoch 93/500\n",
      "2/2 - 0s - loss: 0.5666 - accuracy: 0.2033 - val_loss: 0.5830 - val_accuracy: 0.1849 - 32ms/epoch - 16ms/step\n",
      "Epoch 94/500\n",
      "2/2 - 0s - loss: 0.5667 - accuracy: 0.2084 - val_loss: 0.5833 - val_accuracy: 0.1953 - 29ms/epoch - 15ms/step\n",
      "Epoch 95/500\n",
      "2/2 - 0s - loss: 0.5669 - accuracy: 0.2153 - val_loss: 0.5827 - val_accuracy: 0.1953 - 29ms/epoch - 15ms/step\n",
      "Epoch 96/500\n",
      "2/2 - 0s - loss: 0.5664 - accuracy: 0.2016 - val_loss: 0.5821 - val_accuracy: 0.1953 - 30ms/epoch - 15ms/step\n",
      "Epoch 97/500\n",
      "2/2 - 0s - loss: 0.5667 - accuracy: 0.1852 - val_loss: 0.5825 - val_accuracy: 0.2031 - 31ms/epoch - 16ms/step\n",
      "Epoch 98/500\n",
      "2/2 - 0s - loss: 0.5662 - accuracy: 0.1912 - val_loss: 0.5835 - val_accuracy: 0.2031 - 30ms/epoch - 15ms/step\n",
      "Epoch 99/500\n",
      "2/2 - 0s - loss: 0.5664 - accuracy: 0.1921 - val_loss: 0.5830 - val_accuracy: 0.2083 - 34ms/epoch - 17ms/step\n",
      "Epoch 100/500\n",
      "2/2 - 0s - loss: 0.5662 - accuracy: 0.1981 - val_loss: 0.5821 - val_accuracy: 0.2135 - 30ms/epoch - 15ms/step\n",
      "Epoch 101/500\n",
      "2/2 - 0s - loss: 0.5661 - accuracy: 0.2110 - val_loss: 0.5821 - val_accuracy: 0.2214 - 30ms/epoch - 15ms/step\n",
      "Epoch 102/500\n",
      "2/2 - 0s - loss: 0.5662 - accuracy: 0.2076 - val_loss: 0.5828 - val_accuracy: 0.2422 - 32ms/epoch - 16ms/step\n",
      "Epoch 103/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.1895 - val_loss: 0.5830 - val_accuracy: 0.2396 - 29ms/epoch - 15ms/step\n",
      "Epoch 104/500\n",
      "2/2 - 0s - loss: 0.5658 - accuracy: 0.1929 - val_loss: 0.5824 - val_accuracy: 0.2188 - 29ms/epoch - 14ms/step\n",
      "Epoch 105/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.1929 - val_loss: 0.5821 - val_accuracy: 0.2109 - 29ms/epoch - 15ms/step\n",
      "Epoch 106/500\n",
      "2/2 - 0s - loss: 0.5662 - accuracy: 0.1981 - val_loss: 0.5824 - val_accuracy: 0.2135 - 29ms/epoch - 15ms/step\n",
      "Epoch 107/500\n",
      "2/2 - 0s - loss: 0.5658 - accuracy: 0.2119 - val_loss: 0.5832 - val_accuracy: 0.2214 - 29ms/epoch - 15ms/step\n",
      "Epoch 108/500\n",
      "2/2 - 0s - loss: 0.5661 - accuracy: 0.2110 - val_loss: 0.5832 - val_accuracy: 0.2083 - 30ms/epoch - 15ms/step\n",
      "Epoch 109/500\n",
      "2/2 - 0s - loss: 0.5661 - accuracy: 0.2076 - val_loss: 0.5824 - val_accuracy: 0.2083 - 30ms/epoch - 15ms/step\n",
      "Epoch 110/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.1912 - val_loss: 0.5820 - val_accuracy: 0.2005 - 31ms/epoch - 16ms/step\n",
      "Epoch 111/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.2024 - val_loss: 0.5821 - val_accuracy: 0.1953 - 31ms/epoch - 15ms/step\n",
      "Epoch 112/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.1929 - val_loss: 0.5825 - val_accuracy: 0.1979 - 30ms/epoch - 15ms/step\n",
      "Epoch 113/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.2153 - val_loss: 0.5826 - val_accuracy: 0.1979 - 29ms/epoch - 15ms/step\n",
      "Epoch 114/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.2007 - val_loss: 0.5825 - val_accuracy: 0.1953 - 30ms/epoch - 15ms/step\n",
      "Epoch 115/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.2067 - val_loss: 0.5826 - val_accuracy: 0.1953 - 30ms/epoch - 15ms/step\n",
      "Epoch 116/500\n",
      "2/2 - 0s - loss: 0.5657 - accuracy: 0.1904 - val_loss: 0.5830 - val_accuracy: 0.1953 - 29ms/epoch - 15ms/step\n",
      "Epoch 117/500\n",
      "2/2 - 0s - loss: 0.5658 - accuracy: 0.1990 - val_loss: 0.5829 - val_accuracy: 0.1953 - 31ms/epoch - 15ms/step\n",
      "Epoch 118/500\n",
      "2/2 - 0s - loss: 0.5658 - accuracy: 0.2179 - val_loss: 0.5824 - val_accuracy: 0.1979 - 30ms/epoch - 15ms/step\n",
      "Epoch 119/500\n",
      "2/2 - 0s - loss: 0.5657 - accuracy: 0.2171 - val_loss: 0.5825 - val_accuracy: 0.1979 - 30ms/epoch - 15ms/step\n",
      "Epoch 120/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.1929 - val_loss: 0.5829 - val_accuracy: 0.1953 - 29ms/epoch - 14ms/step\n",
      "Epoch 121/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.2016 - val_loss: 0.5827 - val_accuracy: 0.1953 - 29ms/epoch - 14ms/step\n",
      "Epoch 122/500\n",
      "2/2 - 0s - loss: 0.5659 - accuracy: 0.1998 - val_loss: 0.5825 - val_accuracy: 0.1979 - 30ms/epoch - 15ms/step\n",
      "Epoch 123/500\n",
      "2/2 - 0s - loss: 0.5657 - accuracy: 0.2110 - val_loss: 0.5827 - val_accuracy: 0.1953 - 32ms/epoch - 16ms/step\n",
      "Epoch 124/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.1878 - val_loss: 0.5830 - val_accuracy: 0.1953 - 32ms/epoch - 16ms/step\n",
      "Epoch 125/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.2093 - val_loss: 0.5830 - val_accuracy: 0.1979 - 33ms/epoch - 17ms/step\n",
      "Epoch 126/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.1964 - val_loss: 0.5824 - val_accuracy: 0.1953 - 32ms/epoch - 16ms/step\n",
      "Epoch 127/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.2041 - val_loss: 0.5821 - val_accuracy: 0.1979 - 31ms/epoch - 15ms/step\n",
      "Epoch 128/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2067 - val_loss: 0.5821 - val_accuracy: 0.1979 - 30ms/epoch - 15ms/step\n",
      "Epoch 129/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.2214 - val_loss: 0.5828 - val_accuracy: 0.1979 - 29ms/epoch - 15ms/step\n",
      "Epoch 130/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.2188 - val_loss: 0.5835 - val_accuracy: 0.2031 - 29ms/epoch - 15ms/step\n",
      "Epoch 131/500\n",
      "2/2 - 0s - loss: 0.5654 - accuracy: 0.1998 - val_loss: 0.5833 - val_accuracy: 0.1979 - 31ms/epoch - 15ms/step\n",
      "Epoch 132/500\n",
      "2/2 - 0s - loss: 0.5654 - accuracy: 0.2059 - val_loss: 0.5826 - val_accuracy: 0.1979 - 33ms/epoch - 16ms/step\n",
      "Epoch 133/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2041 - val_loss: 0.5827 - val_accuracy: 0.2031 - 33ms/epoch - 17ms/step\n",
      "Epoch 134/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.2377 - val_loss: 0.5834 - val_accuracy: 0.2057 - 34ms/epoch - 17ms/step\n",
      "Epoch 135/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.1835 - val_loss: 0.5836 - val_accuracy: 0.2031 - 30ms/epoch - 15ms/step\n",
      "Epoch 136/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.1964 - val_loss: 0.5830 - val_accuracy: 0.2057 - 31ms/epoch - 16ms/step\n",
      "Epoch 137/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2016 - val_loss: 0.5826 - val_accuracy: 0.2083 - 31ms/epoch - 16ms/step\n",
      "Epoch 138/500\n",
      "2/2 - 0s - loss: 0.5654 - accuracy: 0.2127 - val_loss: 0.5829 - val_accuracy: 0.2500 - 32ms/epoch - 16ms/step\n",
      "Epoch 139/500\n",
      "2/2 - 0s - loss: 0.5649 - accuracy: 0.1981 - val_loss: 0.5839 - val_accuracy: 0.2760 - 32ms/epoch - 16ms/step\n",
      "Epoch 140/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2145 - val_loss: 0.5843 - val_accuracy: 0.3151 - 30ms/epoch - 15ms/step\n",
      "Epoch 141/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.1938 - val_loss: 0.5828 - val_accuracy: 0.3203 - 30ms/epoch - 15ms/step\n",
      "Epoch 142/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2171 - val_loss: 0.5819 - val_accuracy: 0.3203 - 32ms/epoch - 16ms/step\n",
      "Epoch 143/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2067 - val_loss: 0.5823 - val_accuracy: 0.3203 - 31ms/epoch - 15ms/step\n",
      "Epoch 144/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2231 - val_loss: 0.5837 - val_accuracy: 0.3203 - 32ms/epoch - 16ms/step\n",
      "Epoch 145/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.1981 - val_loss: 0.5841 - val_accuracy: 0.3203 - 32ms/epoch - 16ms/step\n",
      "Epoch 146/500\n",
      "2/2 - 0s - loss: 0.5655 - accuracy: 0.2102 - val_loss: 0.5826 - val_accuracy: 0.3203 - 33ms/epoch - 16ms/step\n",
      "Epoch 147/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.2093 - val_loss: 0.5818 - val_accuracy: 0.3203 - 35ms/epoch - 17ms/step\n",
      "Epoch 148/500\n",
      "2/2 - 0s - loss: 0.5656 - accuracy: 0.2110 - val_loss: 0.5819 - val_accuracy: 0.3203 - 35ms/epoch - 18ms/step\n",
      "Epoch 149/500\n",
      "2/2 - 0s - loss: 0.5654 - accuracy: 0.2084 - val_loss: 0.5826 - val_accuracy: 0.3203 - 31ms/epoch - 15ms/step\n",
      "Epoch 150/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.2196 - val_loss: 0.5830 - val_accuracy: 0.3203 - 32ms/epoch - 16ms/step\n",
      "Epoch 151/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2067 - val_loss: 0.5825 - val_accuracy: 0.3203 - 33ms/epoch - 17ms/step\n",
      "Epoch 152/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.1792 - val_loss: 0.5821 - val_accuracy: 0.3203 - 33ms/epoch - 16ms/step\n",
      "Epoch 153/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2205 - val_loss: 0.5824 - val_accuracy: 0.3203 - 33ms/epoch - 16ms/step\n",
      "Epoch 154/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2093 - val_loss: 0.5828 - val_accuracy: 0.3203 - 32ms/epoch - 16ms/step\n",
      "Epoch 155/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2214 - val_loss: 0.5831 - val_accuracy: 0.3021 - 30ms/epoch - 15ms/step\n",
      "Epoch 156/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.2110 - val_loss: 0.5829 - val_accuracy: 0.2760 - 33ms/epoch - 16ms/step\n",
      "Epoch 157/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.2024 - val_loss: 0.5825 - val_accuracy: 0.2760 - 34ms/epoch - 17ms/step\n",
      "Epoch 158/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2188 - val_loss: 0.5823 - val_accuracy: 0.2708 - 29ms/epoch - 15ms/step\n",
      "Epoch 159/500\n",
      "2/2 - 0s - loss: 0.5654 - accuracy: 0.2024 - val_loss: 0.5827 - val_accuracy: 0.2630 - 29ms/epoch - 15ms/step\n",
      "Epoch 160/500\n",
      "2/2 - 0s - loss: 0.5653 - accuracy: 0.2153 - val_loss: 0.5833 - val_accuracy: 0.2604 - 30ms/epoch - 15ms/step\n",
      "Epoch 161/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.2076 - val_loss: 0.5833 - val_accuracy: 0.2578 - 30ms/epoch - 15ms/step\n",
      "Epoch 162/500\n",
      "2/2 - 0s - loss: 0.5647 - accuracy: 0.2291 - val_loss: 0.5828 - val_accuracy: 0.2500 - 30ms/epoch - 15ms/step\n",
      "Epoch 163/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.2007 - val_loss: 0.5824 - val_accuracy: 0.2526 - 32ms/epoch - 16ms/step\n",
      "Epoch 164/500\n",
      "2/2 - 0s - loss: 0.5649 - accuracy: 0.2059 - val_loss: 0.5824 - val_accuracy: 0.2604 - 34ms/epoch - 17ms/step\n",
      "Epoch 165/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.2162 - val_loss: 0.5832 - val_accuracy: 0.2708 - 33ms/epoch - 16ms/step\n",
      "Epoch 166/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.1972 - val_loss: 0.5837 - val_accuracy: 0.2786 - 30ms/epoch - 15ms/step\n",
      "Epoch 167/500\n",
      "2/2 - 0s - loss: 0.5651 - accuracy: 0.2265 - val_loss: 0.5830 - val_accuracy: 0.2786 - 29ms/epoch - 15ms/step\n",
      "Epoch 168/500\n",
      "2/2 - 0s - loss: 0.5650 - accuracy: 0.2041 - val_loss: 0.5824 - val_accuracy: 0.2760 - 29ms/epoch - 14ms/step\n",
      "Epoch 169/500\n",
      "2/2 - 0s - loss: 0.5652 - accuracy: 0.2050 - val_loss: 0.5826 - val_accuracy: 0.2708 - 30ms/epoch - 15ms/step\n",
      "Epoch 170/500\n",
      "2/2 - 0s - loss: 0.5649 - accuracy: 0.2067 - val_loss: 0.5830 - val_accuracy: 0.2630 - 29ms/epoch - 15ms/step\n",
      "Epoch 171/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.2153 - val_loss: 0.5833 - val_accuracy: 0.2578 - 29ms/epoch - 15ms/step\n",
      "Epoch 172/500\n",
      "2/2 - 0s - loss: 0.5648 - accuracy: 0.2033 - val_loss: 0.5834 - val_accuracy: 0.2292 - 29ms/epoch - 15ms/step\n",
      "Epoch 173/500\n",
      "2/2 - 0s - loss: 0.5647 - accuracy: 0.2067 - val_loss: 0.5831 - val_accuracy: 0.2135 - 29ms/epoch - 15ms/step\n",
      "Epoch 174/500\n",
      "2/2 - 0s - loss: 0.5649 - accuracy: 0.2084 - val_loss: 0.5829 - val_accuracy: 0.2135 - 29ms/epoch - 15ms/step\n",
      "Epoch 175/500\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "history = model.fit(train_X, train_Y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(val_X, val_Y), verbose=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 预测\n",
    "pred_Y = model.predict(test_X).reshape(-1, 1)\n",
    "test_Y = test_Y.reshape(-1, 1)\n",
    "\n",
    "# 反缩放预测结果\n",
    "pred_Y_sc = Scaler.inverse_transform(np.concatenate((pred_Y, np.zeros((len(pred_Y), FEATURES - 1))), axis=1))[:, 0]\n",
    "test_Y_sc = Scaler.inverse_transform(np.concatenate((test_Y, np.zeros((len(test_Y), FEATURES - 1))), axis=1))[:, 0]\n",
    "\n",
    "# 计算预测误差\n",
    "mse = np.mean((pred_Y_sc - test_Y_sc) ** 2)\n",
    "mape = np.mean(np.abs((test_Y_sc - pred_Y_sc) / test_Y_sc)) * 100\n",
    "\n",
    "# 可视化预测结果\n",
    "plt.plot(test_Y_sc, label='True')\n",
    "plt.plot(pred_Y_sc, label='Predictions')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mse, mape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 循环预测"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 预测的后FORECAST_STEPS价格\n",
    "y_hat = Scaler.inverse_transform(np.concatenate((pred_Y, np.zeros((len(pred_Y), FEATURES - 1))), axis=1))[:, 0].reshape(-1, FORECAST_STEPS)\n",
    "y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "plt.plot(y_hat[:, 0], label='Predictions')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "def predict_stock_price():\n",
    "    # input_data = test_X[0]  # 获取测试集最后一个时间步的数据作为起始点\n",
    "    predictions = np.empty((1, 1))  # 存储预测结果\n",
    "    j = 0\n",
    "\n",
    "    # 循环预测\n",
    "    for i in range(len(test_X)):\n",
    "        # 将输入数据重塑为LSTM模型所需的形状\n",
    "        input_data = test_X[j].reshape(1, TIME_STEPS, FEATURES)  # 测试集中第一条数据\n",
    "\n",
    "        # 使用LSTM模型进行预测\n",
    "        pred_y = model.predict(input_data).reshape(-1, 1)\n",
    "        print(j, pred_y)\n",
    "\n",
    "        # 将预测结果添加到预测列表中\n",
    "        predictions = np.concatenate((predictions, pred_y), axis=0)\n",
    "\n",
    "        # 观测期\n",
    "        j += FORECAST_STEPS\n",
    "\n",
    "        if j >= len(test_X):\n",
    "            break\n",
    "\n",
    "    # 对预测结果进行反归一化处理\n",
    "    predictions = np.array(predictions).reshape(-1, 1)\n",
    "    predictions = Scaler.inverse_transform(np.concatenate((predictions, np.zeros((len(predictions), FEATURES - 1))), axis=1))[:, 0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# y_hat = predict_stock_price()\n",
    "# y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 可视化预测结果\n",
    "# plt.plot(test_Y_sc.reshape(-1, 5)[:, 0], label='True')\n",
    "# plt.plot(y_hat, label='Predictions')\n",
    "# plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# y_hat.shape, test_Y_sc.reshape(-1, 5)[:, 0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 投资策略"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_hat"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_real = Scaler.inverse_transform(np.concatenate((test_Y, np.zeros((len(test_Y), FEATURES - 1))), axis=1))[:, 0]\n",
    "y_real = y_real.reshape(-1, 5)\n",
    "y_real"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df_portfolio = pd.DataFrame(np.concatenate((y_hat, y_real), axis=1))\n",
    "\n",
    "# 计算回报\n",
    "df_portfolio['return_hat'] = (df_portfolio[4] - df_portfolio[0]) / df_portfolio[0] * 100\n",
    "df_portfolio['return_real'] = (df_portfolio[9] - df_portfolio[5]) / df_portfolio[5] * 100\n",
    "\n",
    "#隔行保留\n",
    "df_portfolio = df_portfolio[0::FORECAST_STEPS]\n",
    "\n",
    "# 检查 col1 和 col2 是否具有相同的符号\n",
    "df_portfolio['sign_match'] = (df_portfolio['return_real'] * df_portfolio['return_hat']) > 0\n",
    "# 统计 sign_match 中 True 的百分比\n",
    "percent_true = df_portfolio['sign_match'].mean() * 100\n",
    "\n",
    "df_portfolio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "percent_true"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 可视化投资策略"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.plot(df_portfolio[['return_hat']], label='Predictions')\n",
    "plt.plot(df_portfolio[['return_real']], label='True')\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "Rapids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
